{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 285 - MLIP -Assignment 2 - CNNs and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Construct a 5 × 3 tensor and print it with the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.5259e+03,  3.0693e-41,  5.7453e-44],\n",
      "        [ 0.0000e+00,         nan,  1.8040e+28],\n",
      "        [ 1.3733e-14,  6.4076e+07,  2.0706e-19],\n",
      "        [ 7.3909e+22,  2.4176e-12,  1.1625e+33],\n",
      "        [ 8.9605e-01,  1.1632e+33,  5.6003e-02]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5,3)\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s is initialized uniformly between -1 and 1. The size is 5 × 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Construct a randomly initialized matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7025, 0.7128, 0.9659],\n",
      "        [0.3952, 0.8684, 0.7759],\n",
      "        [0.3639, 0.4396, 0.8424],\n",
      "        [0.8514, 0.6016, 0.2780],\n",
      "        [0.7921, 0.7800, 0.8604]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3579,  0.7866,  0.3766],\n",
      "        [-1.1644,  1.4356, -0.8375],\n",
      "        [-0.0796,  1.9458,  1.3393],\n",
      "        [ 0.9975,  1.4079, -0.4626],\n",
      "        [-0.9011,  1.4690,  0.9271]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "y_new = torch.randn(5, 3)\n",
    "print(y_new)\n",
    "print(type(y_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random values in y are in a uniform distribution on the interval [0,1). <br>\n",
    "Random values in y_new in a standard normal distribution on the interval where mean is 0 and variance is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.5259e+03,  3.0693e-41,  5.7453e-44],\n",
      "        [ 0.0000e+00,         nan,  1.8040e+28],\n",
      "        [ 1.3733e-14,  6.4076e+07,  2.0706e-19],\n",
      "        [ 7.3909e+22,  2.4176e-12,  1.1625e+33],\n",
      "        [ 8.9605e-01,  1.1632e+33,  5.6003e-02]], dtype=torch.float64)\n",
      "tensor([[0.7025, 0.7128, 0.9659],\n",
      "        [0.3952, 0.8684, 0.7759],\n",
      "        [0.3639, 0.4396, 0.8424],\n",
      "        [0.8514, 0.6016, 0.2780],\n",
      "        [0.7921, 0.7800, 0.8604]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of x and y are both torch.float64 in size of 5 × 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. We can also initialize directly tensors with prescribed values. Create the following two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[-0.1859, 1.3970, 0.5236],\n",
    "                  [ 2.3854 , 0.0707 , 2.1970] ,\n",
    "                  [ -0.3587 , 1.2359 , 1.8951] ,\n",
    "                  [ -0.1189 , -0.1376, 0.4647],\n",
    "                  [ -1.8968 , 2.0164, 0.1092]])\n",
    "\n",
    "y = torch.Tensor([[0.4838, 0.5822, 0.2755],\n",
    "                  [1.0982, 0.4932, -0.6680],\n",
    "                  [0.7915, 0.6580, -0.5819],\n",
    "                  [0.3825, -1.1822, 1.5217],\n",
    "                  [0.6042, -0.2280, 1.3210]])\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. You can stack the two 2d tensors in a 3d tensor as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "z = torch.stack((x, y))\n",
    "print(z.shape)\n",
    "#print(z)\n",
    "print(torch.cat((x, y), 0).shape)\n",
    "print(torch.cat((x, y), 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of z is 2×5×3. <br>\n",
    "torch.cat((x, y), 0) is in size of 10×3 and torch.cat((x, y), 1) is in size of 5×6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Report the value of the element at the 5th row and 3rd column in the 2d tensor y, and try accessing the same element in the 3d tensor z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(y[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "print(z[1,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Similarly print all the elements corresponding to the 5th row and 3rd column in z. How many elements are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1092, 1.3210])\n"
     ]
    }
   ],
   "source": [
    "print(z[:,4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Adding two tensors is fairly straightforward. There are multiple syntaxes for this operation. Sum x and y (from question 4) as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the methods above print the same output. They are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. To reshape a tensor, you can use torch.view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1839,  1.9871,  0.0265,  0.6882,  0.5445,  1.4473, -0.4190,  0.1325],\n",
      "        [-0.1463,  0.9556,  1.1524,  0.0929,  0.7621, -2.2080, -0.0459,  1.1320]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the effect of each of these instructions:\n",
    "> 1) torch.randn(4,4): initialize 4×4 tensor with random values. <br>\n",
    "> 2) x.view(16): reshape x into 1×16 vector but no changes made in data. <br> \n",
    "> 3) x.view(-1,8): reshape x into a some value × 8 = 16 without changes on data. Since sometimes we don't want give a specific value at the position of -1, then programm will help us to calculate that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Generate 2 random tensors x and y of dimensions 10×10 and 2×100, respectively, resize them such that the instruction torch.mm(x, y) performs a row vector by matrix multiplication resulting in a row vector of dimensions 1 × 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 10)\n",
    "y = torch.randn(2, 100)\n",
    "z = torch.mm(x.view(1, -1), y.view(-1,2))\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Run the below code snippet and report your observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code snippet coverts a from torch.Tensor into a numpy ndarray with length 5. <br> \n",
    "The type of a and b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Let us add one to the ﬁrst element of the tensor a from the previous question and report the new values of a and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They match. And they share their underlying memory locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Compare the eﬀect of each of these three instructions separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 2., 2., 2., 2.]) [3. 2. 2. 2. 2.]\n",
      "tensor([4., 3., 3., 3., 3.]) [4. 3. 3. 3. 3.]\n",
      "tensor([5., 4., 4., 4., 4.]) [4. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a,b)\n",
    "a[:] += 1\n",
    "print(a,b)\n",
    "a = a.add(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) a.add_(1): adds one to all elements in a and b. <br>\n",
    "2) a[:] += 1: adds one to all elements in a and b. <br>\n",
    "3) a.add(1): only adds one to all elements in a which is a torch tensor. The numpy array keeps unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Let us study the reverse operation, converting NumPy arrays to a Torch tensor. Run the following code and examine the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch tensors can be moved onto GPU device’s memory using .to('cuda') or .cuda() and back to CPU device with .to('cpu') or .cpu(). Alternatively, a tensor can be directly allocated into the GPU using the device optional argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Run the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "x = torch.randn(5, 3).to(device)\n",
    "y = torch.randn(5, 3, device=device)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret each of these instructions.\n",
    "> 1) device = 'cuda' if torch.cuda.is_available() else 'cpu': define device as cuda is cuda is available, otherwise use cpu.  <br>\n",
    "> 2) print(device): print current device (cuda or cpu). <br>\n",
    "> 3) if torch.cuda.is_available(): check if cuda (GPU) is available to use. <br>\n",
    "> 4) x = torch.randn(5, 3).to(device): create random tensor x with size 5x3 by cuda/cpu. <br>\n",
    "> 5) y = torch.randn(5, 3, device=device): create random tensor y with size 5x3 by cuda/cpu. <br>\n",
    "> 6) z = x + y: add the two tensors regardless their memory location (GPU or CPU). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would the program produce the same result if it was run on a CPU only architecture?\n",
    "> YES."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Run and interpret the result of the following two instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8537111  -1.9726417  -0.09669566]\n",
      " [ 0.4157565   1.5730537  -0.495484  ]\n",
      " [-1.6940924   0.14636117 -1.9194341 ]\n",
      " [ 0.0340277   1.089397    1.6724252 ]\n",
      " [ 0.90003747 -0.37220216 -1.0800432 ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-11d5c486e6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print(z.cpu().numpy())\n",
    "print(z.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret:\n",
    "> z.cpu().numpy() converts Cuda tensor into numpy. While in data in GPU cannot be converted into numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autograd: automatic diﬀerentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Run the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "None\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The requires_grad attribute of y is True.\n",
    "> The grad attribute of x and y are None (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Run the following script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "f = z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the equation linking f with the four entries of x.\n",
    "> $$ f(x)= \\frac{3(x_1+2)^2+3(x_2+2)^2+3(x_3+2)^2+3(x_4+2)^2}{4} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Because the variable f contains a single scalar, we can now back-propagate the gradient of f with respect to x into the variable x as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "f.backward() # That's it!\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of f with respect to x is : [[4.5, 4.5][4.5, 4.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Based on question 18, try to ﬁgure out mathematically if autograd produces the correct answer by deriving, yourself, the partial derivatives for each $x_i$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (\\nabla_x f(\\mathbf{x})))_i = \\frac {\\partial f(x_1, x_2, x_3, x_4)}{\\partial x_i}$$<br>\n",
    "$$ f(\\mathbf{x})= \\frac{3}{4}\\left \\{(x_1+2)^2+(x_2+2)^2+(x_3+2)^2+(x_4+2)^2\\right\\} $$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_1} = \\frac{3(2+x_1)}{2}\\bigg\\rvert_{x_1 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_2} = \\frac{3(2+x_2)}{2}\\bigg\\rvert_{x_2 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_3} = \\frac{3(2+x_3)}{2}\\bigg\\rvert_{x_3 = 1} = 4.5$$<br>\n",
    "$$ \\frac {\\partial f(\\mathbf{x})}{\\partial x_4} = \\frac{3(2+x_4)}{2}\\bigg\\rvert_{x_4 = 1} = 4.5$$<br>\n",
    "<br>\n",
    "Autograd produces the correct answer. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. MNIST Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. Reuse the code from Assignment 1 to load and normalize MNIST testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MNISTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ltrain = MNISTtools.load(dataset = \"training\", path = \"/datasets/MNIST\")\n",
    "xtest, ltest = MNISTtools.load(dataset = \"testing\", path = \"/datasets/MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    x = x.astype(np.float64) # convert data type\n",
    "    xmax, xmin = x.max(), x.min()  \n",
    "    x = 2 * (x - xmin) / (xmax - xmin) - 1\n",
    "    return x\n",
    "\n",
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "xtest = normalize_MNIST_images(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Reshape data for torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(28, 28, 1, 60000)\n",
    "xtest = xtest.reshape(28, 28, 1, 10000)\n",
    "xtrain = np.moveaxis(xtrain, [3,2],[0,1]) # np.moveaxis(a, source, destination)\n",
    "xtest = np.moveaxis(xtest,[3,2],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Check that your data are well reorganized by making sure that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "%matplotlib inline\n",
    "MNISTtools.show(xtrain[42, 0, :, :])\n",
    "print(ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that our preprocessing is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Finally wrap all the data into torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Convolutional Neural Network (CNN) for MNIST classiﬁcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Input = 1×28×28 <br>\n",
    "(2) Conv1 = 6×24×24 <br>\n",
    "(3) Pool1 = 6×12×12 <br>\n",
    "(4) Conv2 = 16×8×8  <br>\n",
    "(5) Pool2 = 16×4×4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26. Interpret and complete the following code initializing our LeNet network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#This is our neural network class that inherits from nn.Module\n",
    "class LeNet(nn.Module):\n",
    "    \n",
    "    #Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5).double()\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).double()\n",
    "        self.fc1 = nn.Linear(16*4*4, 120).double()\n",
    "        self.fc2 = nn.Linear(120, 84).double()\n",
    "        self.fc3 = nn.Linear(84, 10).double()\n",
    "        \n",
    "    #Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    #determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "    \n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. The learnable parameters of a model are returned by net.parameters(). Run the following and interpret the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters in indices 0 and 1 are learnable parameters. <br> Gradients are going to be tracked by autograd for all parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. To run a forward pass of your initial network over your testing set, simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.4000)\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).ﬂoat().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret the result\n",
    "> On average the prediction is euqal to the test label 11.4000%. This does make sense since there are 10 output classes from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 29. We will use (Mini-Batch) Stochastic Gradient Descent (SGD) with cross-entropy and momentum.\n",
    "\n",
    "#### Start implementing the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]\n",
    "    # Training set size\n",
    "    NB = int(N/B)\n",
    "    # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30. We have everything ready now to train our model with SGD and backprop.\n",
    "\n",
    "#### Finish implementing backprop deep by completing each part in the piece of code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.300\n",
      "[1,   200] loss: 2.293\n",
      "[1,   300] loss: 2.283\n",
      "[1,   400] loss: 2.271\n",
      "[1,   500] loss: 2.245\n",
      "[1,   600] loss: 2.186\n",
      "[2,   100] loss: 1.999\n",
      "[2,   200] loss: 1.386\n",
      "[2,   300] loss: 0.750\n",
      "[2,   400] loss: 0.474\n",
      "[2,   500] loss: 0.349\n",
      "[2,   600] loss: 0.323\n",
      "[3,   100] loss: 0.266\n",
      "[3,   200] loss: 0.235\n",
      "[3,   300] loss: 0.226\n",
      "[3,   400] loss: 0.213\n",
      "[3,   500] loss: 0.196\n",
      "[3,   600] loss: 0.178\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0]\n",
    "    # Training set size\n",
    "    NB = int(N/B)\n",
    "    # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(NB)  # shuffling\n",
    "        for k in range(NB):\n",
    "            i = shuffled_indices[k]  # index of the minibatch\n",
    "\n",
    "            # Extract the i-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = range(i*B, min((i+1)*B,N))  # indicies of the sample for the i-th minibatch\n",
    "            inputs = xtrain[minibatch_indices,:,:,:]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "\n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "\n",
    "            #Print averaged loss per minibatch every 100 minibatches\n",
    "            running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, k + 1, running_loss/100))\n",
    "                running_loss = 0.0\n",
    "    print(\"Finished Training\")\n",
    "                \n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When T equals 3, the accuracy increases from 8.92% to 2.30% (67.5%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. Re-evaluate the predictions of your trained network on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.305\n",
      "[2,   100] loss: 2.297\n",
      "[3,   100] loss: 2.287\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "backprop_deep(xtest, ltest, net, T=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yinit = net(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.2000)\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).ﬂoat().mean())\n",
    "#print(100*np.mean(ltest == yinit.data.numpy().T.argmax(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. Move the training data to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.302\n",
      "[1,   200] loss: 2.292\n",
      "[1,   300] loss: 2.276\n",
      "[1,   400] loss: 2.247\n",
      "[1,   500] loss: 2.179\n",
      "[1,   600] loss: 1.945\n",
      "[2,   100] loss: 1.446\n",
      "[2,   200] loss: 0.984\n",
      "[2,   300] loss: 0.829\n",
      "[2,   400] loss: 0.684\n",
      "[2,   500] loss: 0.586\n",
      "[2,   600] loss: 0.496\n",
      "[3,   100] loss: 0.464\n",
      "[3,   200] loss: 0.395\n",
      "[3,   300] loss: 0.360\n",
      "[3,   400] loss: 0.308\n",
      "[3,   500] loss: 0.283\n",
      "[3,   600] loss: 0.259\n",
      "[4,   100] loss: 0.246\n",
      "[4,   200] loss: 0.226\n",
      "[4,   300] loss: 0.212\n",
      "[4,   400] loss: 0.216\n",
      "[4,   500] loss: 0.191\n",
      "[4,   600] loss: 0.180\n",
      "[5,   100] loss: 0.166\n",
      "[5,   200] loss: 0.163\n",
      "[5,   300] loss: 0.160\n",
      "[5,   400] loss: 0.152\n",
      "[5,   500] loss: 0.158\n",
      "[5,   600] loss: 0.141\n",
      "[6,   100] loss: 0.139\n",
      "[6,   200] loss: 0.134\n",
      "[6,   300] loss: 0.128\n",
      "[6,   400] loss: 0.126\n",
      "[6,   500] loss: 0.127\n",
      "[6,   600] loss: 0.115\n",
      "[7,   100] loss: 0.125\n",
      "[7,   200] loss: 0.116\n",
      "[7,   300] loss: 0.108\n",
      "[7,   400] loss: 0.117\n",
      "[7,   500] loss: 0.109\n",
      "[7,   600] loss: 0.095\n",
      "[8,   100] loss: 0.111\n",
      "[8,   200] loss: 0.098\n",
      "[8,   300] loss: 0.104\n",
      "[8,   400] loss: 0.087\n",
      "[8,   500] loss: 0.099\n",
      "[8,   600] loss: 0.098\n",
      "[9,   100] loss: 0.090\n",
      "[9,   200] loss: 0.089\n",
      "[9,   300] loss: 0.104\n",
      "[9,   400] loss: 0.094\n",
      "[9,   500] loss: 0.080\n",
      "[9,   600] loss: 0.081\n",
      "[10,   100] loss: 0.090\n",
      "[10,   200] loss: 0.085\n",
      "[10,   300] loss: 0.075\n",
      "[10,   400] loss: 0.088\n",
      "[10,   500] loss: 0.082\n",
      "[10,   600] loss: 0.077\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "xtrain = xtrain.to(device)\n",
    "ltrain = ltrain.to(device)\n",
    "net = LeNet().to(device)\n",
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. Re-evaluate the predictions of your trained network on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.300\n",
      "[2,   100] loss: 2.294\n",
      "[3,   100] loss: 2.287\n",
      "[4,   100] loss: 2.276\n",
      "[5,   100] loss: 2.252\n",
      "[6,   100] loss: 2.192\n",
      "[7,   100] loss: 1.978\n",
      "[8,   100] loss: 1.435\n",
      "[9,   100] loss: 0.859\n",
      "[10,   100] loss: 0.605\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "xtest = xtest.to(device)\n",
    "ltest = ltest.to(device)\n",
    "with torch.no_grad():\n",
    "    yinit = net(xtest)\n",
    "net = LeNet().to(device)\n",
    "backprop_deep(xtest, ltest, net, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.8800, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).ﬂoat().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The accuracy improved by from 11.40% - 97.88%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
